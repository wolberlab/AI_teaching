{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung von Maschinellem Lernen in Virtuelle Screening-Kampagnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willkommen zu diesem praktischen Kurs über die Anwendung von maschinellem Lernen (ML) im virtuellen Screening (VS) für die Arzneimittelentdeckung!\n",
    "Dieser Kurs setzt keine Vorkenntnisse in ML voraus, und alle Schritte werden erklärt. In diesem Notizbuch werden Sie die wichtigsten ML-Konzepte verstehen, lernen, wie man Daten von chemischen Verbindungen verarbeitet, ML-Modelle trainiert und virtuelles Screening durchführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abschnitt 1: Einführung in die Schlüsselkonzepte\n",
    "\n",
    "### Grundbegriffe\n",
    "\n",
    "**Virtuelles Screening (VS)** ist eine computergestützte Methodik zur Ermittlung potenzieller Arzneimittelkandidaten aus großen Molekülbibliotheken. Das virtuelle Screening kann sowohl mit ligandenbasierten Ansätzen wie QSAR-Modellen oder Klassifikatoren des maschinellen Lernens als auch mit strukturbasierten Methoden wie molekularem Docking und Pharmakophormodellierung durchgeführt werden. Heute wird das Training von ML-Klassifikatoren für VS ausprobiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VS](./figures/VS.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit **Maschinellem Lernen (ML)** können wir Modelle erstellen, die aus bekannten Daten lernen, um die Aktivität von unbekannten Verbindungen vorherzusagen.\n",
    "\n",
    "Heute wird **Überwachtes Lernen**/**Supervised Learning** angewendet werden, beidem wir beschriftete Datensätze verwenden, um unser Modelle zu trainieren.\n",
    "\n",
    "Zudem wird es sich um **Binäre Klassifizierung**/**Binary Classification** drehen, bei der wir voraussagen, ob eine Verbindung aktiv oder inaktiv ist, aber nicht einen genauen Wert bestimmen(z. B. IC50-Wert, KI...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-Modelle:\n",
    "Im heutigen Praktikum beschäftigen wir uns mit vier verschiedenen klassischen ML-Modelltypen:\n",
    "\n",
    "### Random Forest (RF)\n",
    "Ein Ensemble-Lernverfahren, das mehrere Entscheidungsbäume erzeugt und deren Vorhersagen kombiniert, um die Genauigkeit zu erhöhen und Überanpassung zu verringern. Es ist robust, eignet sich für Klassifikation und Regression und arbeitet zuverlässig mit störbehafteten oder unvollständigen Daten, wie sie in der Arzneistoffforschung aufgrund experimenteller Varianz häufig auftreten.\n",
    "\n",
    "![RF](./figures/RF.png)\n",
    "\n",
    "Der **Random Forest (RF)** besteht aus vielen einzelnen Entscheidungsbäumen, die jeweils unterschiedliche Entscheidungsregeln lernen. Jeder Baum betrachtet dabei nur einen Teil der Daten und Merkmale, sodass eine Vielfalt an Modellen entsteht. Am Ende werden die Vorhersagen der Bäume entweder gemittelt (bei Regression) oder per Mehrheitsentscheidung zusammengefasst (bei Klassifikation). Dadurch wird das Gesamtmodell robust gegen Überanpassung und liefert meist stabilere Ergebnisse als ein einzelner Baum.\n",
    "\n",
    "### Support Vector Machine (SVM)\n",
    "Ein leistungsstarker Supervized-Lerning-Algorithmus, der eine optimale Trennlinie (Hyperplane) findet, um Daten in Klassen zu unterteilen. Er eignet sich besonders für hochdimensionale Daten und klare Trennungen zwischen Klassen.\n",
    "\n",
    "![SVM](./figures/SVM.png)\n",
    "\n",
    "Eine **Support Vector Machine (SVM)** versucht, die beiden Klassen durch eine moeglichst klare Trennlinie zu separieren. Diese Grenze wird so gewählt, dass der Abstand zu den naechstliegenden Datenpunkten maximal ist. Liegt der Datensatz nicht linear trennbar, nutzt die SVM sogenannte Kernelfunktionen, um den Raum so zu transformieren, dass eine Trennung dennoch möglich wird. Am Ende entscheidet die Position eines neuen Punktes relativ zu dieser Trennfläche darueber, zu welcher Klasse er gehoert.\n",
    "\n",
    "### k-Nearest Neighbors (kNN) \n",
    "Ein einfacher, instanzbasierter Algorithmus, der einen Datenpunkt anhand der Eigenschaften seiner ‚k‘ nächsten Nachbarn klassifiziert. Er ist intuitiv, nicht-parametrisch und eignet sich am besten für kleinere, gut verteilte Datensätze.\n",
    "\n",
    "![KNN](./figures/KNN.png)\n",
    "\n",
    "Beim **k-Nearest-Neighbors-Algorithmus (kNN)** wird keine explizite Trainingsphase durchgeführt. Stattdessen werden neue Datenpunkte danach klassifiziert, wie ähnlich sie den bestehenden Punkten im Datensatz sind. Dafür sucht kNN die k nächsten Nachbarn eines neuen Punktes im Merkmalsraum und bestimmt dann, zu welcher Klasse die Mehrheit dieser Nachbarn gehört. Die Qualität der Vorhersage hängt stark von der Wahl von k und der verwendeten Distanzmetrik ab.\n",
    "\n",
    "\n",
    "### Neuronales Netzwerk (NN)\n",
    "Ein rechnerisches Modell, das vom menschlichen Gehirn inspiriert ist und aus Schichten miteinander verbundener Knoten (Neuronen) besteht. NNs erkennen komplexe, nichtlineare Muster und werden häufig in Bereichen wie Bilderkennung oder Sprachverarbeitung eingesetzt. Klassische NNs benötigen oft große Datenmengen, weshalb sie in der frühen Arzneistoffforschung meist suboptimal sind. Aufgrund ihrer enormen Vorhersagekraft werden sie jedoch stetig weiterentwickelt, um auch auf kleinere Datensätze angewendet werden zu können.\n",
    "\n",
    "![NN](./figures/NN.png)\n",
    "\n",
    "Beim **Neuronalen Netzwerk (NN)** durchlaufen die Daten zunächst den Input Layer, der die Merkmale einfach entgegennimmt. Anschliessend werden sie in den Hidden Layers weiterverarbeitet, wo Gewichte und Aktivierungsfunktionen Schritt fuer Schritt immer komplexere Muster herausarbeiten. Im Output Layer werden diese transformierten Informationen dann in eine finale Vorhersage überführt. Währen des Trainings passt das Netzwerk seine Gewichte so an, dass die Ausgaben zunehmend besser zu den wahren Zielwerten passen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation von Molekülen im Computer\n",
    "\n",
    "Bevor Moleküle in ein ML-Modell eingespeist werden können, müssen sie computerlesbar gemacht werden. Eine verbreitete Möglichkeit ist die Darstellung als **SMILES** (Simplified Molecular Input Line Entry System). SMILES kodiert die Molekülstruktur als Textstring, z. B. `\"CCO\"` für Ethanol. SMILES ist praktisch zur Speicherung und für chemische Datenbanken, wird aber für Machine Learning oft nicht direkt genutzt. Der Grund ist, dass ML-Modelle typischerweise **gleich lange numerische Eingaben** erwarten, während SMILES-Strings je nach Molekül unterschiedlich lang sind.  \n",
    "\n",
    "Deshalb werden Moleküle in **Fingerprints** umgewandelt, die eine feste Länge haben und die chemische Struktur numerisch repräsentieren.  \n",
    "\n",
    "**ECFP-Fingerprints**\n",
    "\n",
    "Eine verbreitete Art von Fingerprints sind die **Extended-Connectivity Fingerprints (ECFPs)**. Sie bilden lokale atomare Umgebungen kreisförmig ab. Ausgehend von einem definierten Radius erfassen verschiedene ECFP-Varianten Substrukturen unterschiedlicher Größe: ECFP4 entspricht einem Radius von 2 (bis zu zwei Bindungen vom Zentralatom entfernt, auch Morgan2 genannt), ECFP6 einem Radius von 3 (Morgan3).  \n",
    "\n",
    "![ECFP](./figures/ECFP.png)\n",
    "\n",
    "Beim Fingerprinting bekommt jedes Atom zunächst eine Kennung, die seine Eigenschaften wie Ordnungszahl, Valenz und Bindungen beschreibt. Diese Kennungen werden iterativ aktualisiert, indem Informationen von benachbarten Atomen und Bindungen hinzugefügt werden – so viele Schritte, wie der gewählte Radius vorgibt. Am Ende entsteht für jede kreisförmige Unterstruktur ein eindeutiger Identifikator, der als binärer Vektor dargestellt wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistische Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine statistische Evaluation prüft, ob ein ML Modell wirklich verallgemeinert und nicht nur Zufallsmuster gelernt hat. Sie macht die Leistungsfaehigkeit messbar und zeigt, wie stabil und verlaesslich die Vorhersagen tatsaechlich sind. \n",
    "Ein zentraler Bestandteil ist dabei die Verwendung von Daten, die das Modell waehrend des Trainings nie gesehen hat, denn nur so laesst sich beurteilen,\n",
    "ob es echte Zusammenhaenge erfasst oder lediglich die Trainingsdaten reproduziert.\n",
    "\n",
    "Vor dem eigentlichen **Training** werden die Daten in ein **Trainingset** und ein **Testset** aufgeteilt. Häufig geschieht das zufällig im Verhältnis 80-20, doch es gibt auch ausgefeiltere Vorgehensweisen. Bei einem **Cluster-Split** werden etwa chemisch ähnliche Substanzen gruppiert und dem Modell während des Trainings ganze Gruppen für die Evaluation vorenthalten. Ein **Stratified-Split** hingegen sorgt dafuer, dass wichtige Klassenverhaeltnisse, zum Beispiel aktiv und inaktiv, in beiden Datensaetzen gleichmaessig erhalten bleiben. Zusätzlich kann man **k-Fold Cross-Validation** nutzen, bei der die Daten in k Teilmengen aufgeteilt werden und das Modell k Mal trainiert und getestet wird, sodass jede Teilmenge einmal als Testset dient, was robustere und stabilere Leistungsschätzungen liefert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Leistung eines Modells im **Test** zu bewerten, wird häufig eine **Confusion-Matrix** eingesetzt – dies gilt jedoch nur für **Klassifikationsmodelle**. Sie zeigt auf einen Blick, wie viele Vorhersagen richtig oder falsch waren und unterscheidet dabei zwischen den verschiedenen Klassen – zum Beispiel „aktiv“ versus „inaktiv“. Dadurch lässt sich nicht nur die Gesamtgenauigkeit beurteilen, sondern auch erkennen, ob das Modell bestimmte Klassen systematisch überschätzt oder unterschätzt. Für **Regressionsmodelle** werden stattdessen andere Metriken wie z. B. Mean Squared Error (MSE), Mean Absolut Error (MAE) oder R² verwendet. Die Confusion-Matrix ist somit ein zentrales Werkzeug, um die Stärken und Schwächen eines **Klassifikationsmodells** im Detail zu verstehen und gezielt Verbesserungen vorzunehmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "**Confusion Matrix(Verwirrungsmatrix:)**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}\n",
    "\\text{} & \\text{Predicted Positive} & \\text{Predicted Negative} \\\\\\hline\n",
    "\\text{Actual Positive} & TP & FN \\\\\n",
    "\\text{Actual Negative} & FP & TN\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathrm{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "$$ \\mathrm{Precision} = \\frac{TP}{TP + FP} $$\n",
    "$$ \\mathrm{Recall} = \\frac{TP}{TP + FN} $$\n",
    "$$ \\mathrm{Specificity} = \\frac{TN}{TN + FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus einer **Confusion-Matrix** lassen sich vier zentrale Kennzahlen ableiten, die das Modellverhalten präzise beschreiben:\n",
    "\n",
    "- **Accuracy**: Anteil aller korrekt klassifizierten Proben an der Gesamtzahl der Proben; gibt einen allgemeinen Überblick über die Modellleistung.  \n",
    "- **Precision** (auch *Positive Predictive Value*): Anteil der tatsächlich positiven Fälle unter den vom Modell als positiv vorhergesagten; misst die Zuverlässigkeit positiver Vorhersagen.  \n",
    "- **Recall** (oder *Sensitivität*): Anteil der korrekt erkannten positiven Fälle; zeigt, wie gut das Modell die positiven Klassen erfasst.  \n",
    "- **Spezifität** (*Specificity*): Anteil der korrekt erkannten negativen Fälle; bewertet, wie zuverlässig das Modell negative Klassen identifiziert.\n",
    "\n",
    "Diese Kennzahlen ergänzen sich und liefern zusammen ein differenziertes Bild der Modellleistung, das über die einfache Gesamtgenauigkeit hinausgeht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC-Kurve**:\n",
    "\n",
    "![ROC](./figures/roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Receiver Operating Characteristic (ROC)-Kurve** visualisiert die Leistungsfähigkeit eines Modells über verschiedene Schwellenwerte hinweg. Sie wird erzeugt, indem die Wahr-Positiv-Rate (TPR) gegen die Falsch-Positiv-Rate (FPR) für unterschiedliche Schwellenwerte aufgetragen wird. Die Fläche unter der ROC-Kurve (**ROC-AUC**) quantifiziert die Fähigkeit des Modells, richtig die Klasse zu erkennen. Die ROC-AUC wird dabei nicht nur zur Bewertung von maschinellen Lernmodellen verwendet, sondern auch zur Beurteilung anderer Methoden, wie etwa 3D-Pharmacophore-Modelle und Docking-Ergebnisse in virtuellen Screening-Kampagnen oder auch klinischen Tests.  \n",
    "\n",
    "Wir definieren die Wahr-Positiv-Rate \\(t(x)\\) und die Falsch-Positiv-Rate \\(f(x)\\) als Funktionen eines geeigneten Parameters \\(x \\in [0,1]\\), beispielsweise einer Klassifizierungsschwelle oder einer Variablen, die bestimmt, ob ein Molekül in ein 3D-Pharmakophormodell passt. Unter der Annahme, dass \\(f\\) invertierbar ist, lässt sich die Fläche unter der ROC-Kurve (AUC) folgendermaßen ausdrücken:\n",
    "\n",
    "$$ \\mathrm{AUC} = \\int_0^1 t\\big(f^{-1}(x)\\big) \\, dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung des chemischen Raums\n",
    "\n",
    "Um einschätzen zu können, wo sich unser Trainingsdatensatz im chemischen Raum befindet, ist eine Visualisierung hilfreich. Modelle funktionieren in der Regel nur innerhalb eines bestimmten Bereichs der chemischen Variabilität; außerhalb dieser **Applicability Domain** liefern sie oft zufällige oder sogar falsche Vorhersagen.\n",
    "\n",
    "**Datenvisualisierung mit PCA:**  \n",
    "Die Hauptkomponentenanalyse (PCA) ist eine zentrale Technik zur Visualisierung und Interpretation hochdimensionaler Daten, wie z.B. **Fingerprints**. Molekulare Deskriptoren oder Fingerabdrücke können sich über Hunderte oder Tausende Dimensionen erstrecken, was direkte Interpretationen erschwert. Die PCA transformiert diesen hochdimensionalen Raum in einen niedrigdimensionalen Raum und bewahrt dabei die wichtigsten Varianzquellen. So können Forscher komplexe Datensätze visualisieren und die Lage von Verbindungen in verschiedenen chemischen Räumen vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abschnitt 2: Modelle Selbst Trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 1: Laden der benötigten Python-Bibliotheken\n",
    "\n",
    "Zu Beginn aktivieren wir einige Python-Bibliotheken, die Funktionen bereitstellen, die wir im Verlauf des Praktikums nutzen, ohne sie von Grund auf neu schreiben zu müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # eine Bibliothek zur Datenverarbeitung, ähnlich wie eine Tabellenkalkulation (Excel)\n",
    "                     \n",
    "\n",
    "import numpy as np  # eine Bibliothek für numerische Operationen\n",
    "                    \n",
    "\n",
    "from rdkit import Chem  # eine Bibliothek für Chemoinformatik\n",
    "from rdkit.Chem import AllChem, Draw  \n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "\n",
    "import matplotlib.pyplot as plt # eine Bibliothek zum Erstellen von Diagrammen\n",
    "\n",
    "from sklearn.decomposition import PCA  # eine Bibliothek zur Dimensionsreduktion\n",
    "from sklearn.preprocessing import StandardScaler  # eine Bibliothek zur Skalierung von Daten – für PCA ist die Skalierung besonders wichtig   \n",
    "from physicochem_properties_for_pca import *  # eine Bibliothek mit Funktionen zur Berechnung physikochemischer Eigenschaften für die PCA         \n",
    "                         \n",
    "from sklearn.model_selection import train_test_split # eine Bibliothek zum Aufteilen der Daten in Trainings- und Testdatensätze\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc # eine Bibliothek zur Berechnung von ROC-Kurven und AUC-Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im näachsten Schritt aktiviert ihr das Modell, welches ihr im verlauf des Praktikums verwenden werdet.\n",
    "\n",
    "Entfernt dafür das \\# vor dem entsprechenden Import um die Zeile von einem Kommentar in eine Funktion zu ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier # eine Bibliothek für Random Forest Klassifikatoren\n",
    "#from sklearn.svm import SVC # eine Bibliothek für Support Vector Machine Klassifikatoren\n",
    "#from sklearn.neighbors import KNeighborsClassifier # eine Bibliothek für k-Nearest Neighbors Klassifikatoren\n",
    "#from sklearn.neural_network import MLPClassifier # eine Bibliothek für Neuronale Netzwerke zur Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Laden des Datensatzes\n",
    "\n",
    "Im nächsten Schritt werden die vorbereiteten Trainingsdatensätze geladen. Üblicherweise muss ein Datensatz vor dem Training sorgfältig aufbereitet und bereinigt werden, um ein optimales Modell zu erhalten, da große Datenbanken wie ChEMBL oft widersprüchliche oder fehlerhafte Einträge enthalten. Um Zeit zu sparen, verwenden wir im Praktikum bereits vorbereitete und für das Training von ML-Modellen geeignete Datensätze. Tragt dazu bittte den entsprechenden Dateipfad in die Funtion ein.\n",
    "\n",
    "#### PPAR-γ:\n",
    "\n",
    "PPAR-γ (Peroxisome Proliferator-Activated Receptor Gamma) ist ein nuklearer Hormonrezeptor und Transkriptionsfaktor, der eine zentrale Rolle bei der Regulierung der Genexpression spielt, die am Glukosestoffwechsel, der Lipidhomöostase, Entzündungen und der Adipozytendifferenzierung beteiligt sind.\n",
    "\n",
    "**Klinische Relevanz**\n",
    "**Typ-2-Diabetes mellitus (T2DM):**  \n",
    "**PPAR-γ-Agonisten** wie **Pioglitazon** und **Rosiglitazon** verbessern die Insulinempfindlichkeit und werden als Antidiabetika eingesetzt.\n",
    "\n",
    "**Metabolisches Syndrom:** \n",
    "PPAR-γ kann den Lipid- und Glukosestoffwechsel beeinflussen und ist damit ein therapeutisches Ziel.\n",
    "\n",
    "**Entzündung und Atherosklerose:** \n",
    "PPAR-γ wirkt entzündungshemmend und beeinflusst die Makrophagenaktivität, was einen Zusammenhang mit Herz-Kreislauf-Erkrankungen herstellt.\n",
    "\n",
    "**Krebs:** \n",
    "PPAR-γ kann je nach Gewebekontext tumorfördernde oder -hemmende Wirkungen haben und wird als potenzielles Ziel in der Onkologie untersucht.\n",
    "\n",
    "**Dateipfad**:\n",
    "\n",
    "#### AA2A:\n",
    "\n",
    "Der **A2A-Rezeptor** (Adenosin A2A-Rezeptor) ist ein G-Protein-gekoppelter Rezeptor (GPCR), der vor allem auf Immun- und Nervenzellen exprimiert wird. Er vermittelt seine Wirkung durch Aktivierung der Adenylylcyclase, erhöht cAMP-Spiegel und moduliert zahlreiche zelluläre Signalwege. Der A2A-Rezeptor spielt eine zentrale Rolle bei der Regulation von Entzündungsprozessen, neuronaler Aktivität und der Immunantwort.\n",
    "\n",
    "**Klinische Relevanz**  \n",
    "**Entzündliche Erkrankungen:**  \n",
    "A2A-Rezeptor-Agonisten oder -Antagonisten modulieren die Immunantwort, wodurch entzündliche Prozesse gedämpft oder aktiviert werden können.\n",
    "\n",
    "**Neurologische Erkrankungen:**  \n",
    "Der A2A-Rezeptor ist im Striatum stark exprimiert und beeinflusst dopaminerge Signalwege. Antagonisten werden im Kontext der **Parkinson-Erkrankung** zur Verbesserung motorischer Funktionen untersucht.  \n",
    "**Coffein:** Coffein wirkt als natürlicher **Antagonist am A2A-Rezeptor**. Durch die Blockade der hemmenden Wirkung von Adenosin steigert Coffein Wachheit, Aufmerksamkeit und neuronale Aktivität und kann subtile Effekte auf Motivation und Bewegung ausüben.\n",
    "\n",
    "**Krebsimmuntherapie:**  \n",
    "Durch seine Wirkung auf T-Zellen kann der A2A-Rezeptor das Tumormikromilieu unterdrücken. Inhibitoren des A2A-Rezeptors werden daher als potenzielle Immuntherapeutika in der Onkologie erforscht.\n",
    "\n",
    "**Kardiovaskuläre Effekte:**  \n",
    "Der Rezeptor moduliert Gefäßtonus und Herzfrequenz und ist damit ein Ziel für kardiovaskuläre Erkrankungen wie Ischämie und Herzinfarkt.\n",
    "\n",
    "**Dateipfad**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATEIPFAD/ZUM/DATENSATZ', delimiter=';') #  Laden des Datensatzes in ein Pandas-Dataframe\n",
    "                                                                                \n",
    "df # Anzeige des Dataframe, sieht aus wie ein Tabellenblatt in Excel aus (nur das Anklicken machen wir hier nicht mit der Maus sondern mit Code)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) # Anzeige der ersten 10 Zeilen des Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Betrachten unseres Datensatzes\n",
    "\n",
    "Im nächsten Schritt verschaffen wir uns einen Überblick über unseren Trainingsdatensatz und die darin enthaltenen Moleküle. So können wir einschätzen, in welchem chemischen Raum sich die Daten bewegen und wie vielfältig die Verbindungen sind. Zur Visualisierung nutzen wir eine PCA auf Basis der physikochemischen Eigenschaften der Moleküle. Gleichzeitig beziehen wir als Referenz die **DrugBank** ein, eine Datenbank zugelassener und in klinischen Tests befindlicher Arzneimittel, um den chemischen Raum besser einordnen zu können.\n",
    "\n",
    "\n",
    "Zuerst berechnen wir die physikochemischen Eigenschaften unseres Datensatzes und kontrollieren, dass alles korrekt berechnet wurde. Am Ende sollte eine Liste erscheinen, die die für die PCA relevanten Eigenschaften enthält:\n",
    "\n",
    "['N',\n",
    " 'O',\n",
    " 'chiral',\n",
    " 'MW',\n",
    " 'heavy_atoms',\n",
    " 'h_acc',\n",
    " 'h_don',\n",
    " 'logP',\n",
    " 'TPSA',\n",
    " 'numAro',\n",
    " 'formalCharge',\n",
    " 'numRings',\n",
    " 'frac_csp3',\n",
    " 'S',\n",
    " 'nHalogens',\n",
    " 'MR',\n",
    " '2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der physikochemischen Eigenschaften der Moleküle\n",
    "get_physicochemical_properties(df,'preprocessedSmiles')\n",
    "get_further_physicochemical_properties(df)\n",
    "\n",
    "# Bestätigung, dass nur die Merkmals-Spalten für die Analyse ausgewählt sind\n",
    "featureList = []\n",
    "for column in df.columns:  #deselect the columns that are not features\n",
    "                                # die Spalten, die keine Merkmale sind, abwählen\n",
    "        if column not in ['Molecule ChEMBL ID', 'y_true_label', 'preprocessedSmiles', 'Molecule']:\n",
    "                featureList.append(column)\n",
    "# show the feature list to confirm \n",
    "# die Feature-Liste anzeigen, um zu bestätigen\n",
    "featureList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun laden wir die DrugBank und berechnen ebenfalls die physikochemischen Eigenschaften. Gebt dazu den Dateipfad zur DrugBank in der entsprechenden Funktion an.\n",
    "\n",
    "**Dateipfad**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der DrugBank\n",
    "df_drugbank = pd.read_csv('PFAD/ZUR/DRUGBANK') \n",
    "df_drugbank.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the feature list same as above\n",
    "get_physicochemical_properties(df_drugbank, 'preprocessedSmiles')\n",
    "get_further_physicochemical_properties(df_drugbank)\n",
    "\n",
    "# Auswählen der physikochemischen Merkmale \n",
    "df_drugbank = df_drugbank[['preprocessedSmiles', 'DATABASE_ID'] + featureList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun beschriften wir die beiden Datensätze und führen sie anschließend zusammen, um die PCA auf einer einheitlichen Datenbasis berechnen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beschriften der DrugBank-Daten\n",
    "df_drugbank['label'] = 'DrugBank' \n",
    "\n",
    "#Beschriften der Trainingsdaten mit 'Active' und 'Inactive'\n",
    "df['label'] = df['y_true_label'].apply(lambda x: 'Active' if x == 1 else 'Inactive')\n",
    "\n",
    "# Zusammenführen der beiden Dataframes\n",
    "df_merged = pd.concat([df, df_drugbank], axis=0, ignore_index=True)\n",
    "df_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun führen wir eine PCA-Analyse auf Basis der physikochemischen Eigenschaften der Trainingsdaten und der DrugBank durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_merged.loc[:, featureList].values # X Werte für die PCA\n",
    "y = df_merged.loc[:, ['label']].values # Y Werte zur Beschriftung\n",
    "\n",
    "\n",
    "# Standardisierung der Daten, dies ist wichtig für PCA, da sonst die Ergebnisse durch den Maßstab der Eigenschaften (verschiedene Einheiten) verzerrt werden\n",
    "x = StandardScaler().fit_transform(x) \n",
    "\n",
    "# Durchführung der PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "variance = pca.explained_variance_ratio_\n",
    "principalDF = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n",
    "pcaDF = pd.concat([principalDF, df_merged[['label']]], axis=1)\n",
    "pcaDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun erstellen wir eine Funktion um die PCA Visualisieren zu können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(pcaDF,variance,databases,colors):\n",
    "    plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "    plt.rcParams['figure.figsize'] = 5, 5\n",
    "    fig = plt.figure(dpi=300)\n",
    "    axes = fig.add_subplot()\n",
    "    axes.set_xlabel('PC1 ({:.2%})'.format(variance[0]), fontsize=16)\n",
    "    axes.set_ylabel('PC2 ({:.2%})'.format(variance[1]), fontsize=16)\n",
    "\n",
    "    for database, color in zip(databases, colors):\n",
    "        indicesToKeep = pcaDF['label'] == database\n",
    "        axes.scatter(pcaDF.loc[indicesToKeep, 'PC1'], pcaDF.loc[indicesToKeep, 'PC2'], c=color, s=5,alpha=0.8)\n",
    "    axes.legend(databases, fontsize=15, loc='upper left', scatterpoints=5)\n",
    "\n",
    "    plt.tick_params(labelsize=12)\n",
    "\n",
    "    axes.set_yticks([-5,0,5,10,15])\n",
    "    axes.set_xticks([-5,0,5,10,15])\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(pcaDF,variance,[ 'DrugBank', 'Active', 'Inactive'],['#c5c9c7','#145c37', 'yellow']) # Ändert gern die Farben und Datenbanken nach Belieben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Datenvorbereitung und Fingerprintgenerierung\n",
    "\n",
    "Nun generieren wir ECFPs für unseren Trainingsdatensatz mithilfe von RDKit. Gebt dazu den gewünschten Radius für den Fingerprint in der entsprechenden Funktion an. Wir starten zunächst mit Radius 2; später könnt ihr gerne längere Radii oder eine größere Bitlänge ausprobieren, wenn ihr die Modelle trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Generierung von Morgan-Fingerprints (ECFPs) für jedes Molekül definieren\n",
    "def mol2fingerprint(mol):\n",
    "    # Generate Morgan fingerprint\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=RADIUS, nBits=2048)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "# Anwenden der Funktion auf den Datensatz, um Fingerprints zu generieren\n",
    "df['fingerprint'] = df['preprocessedSmiles'].apply(lambda x: mol2fingerprint(Chem.MolFromSmiles(x)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Fingerprint-Spalte in einzelne Spalten für jede Bit-Position um die Daten für ML-Modelle vorzubereiten\n",
    "morgan2_cols = ['morgan2_b'+str(i) for i in list(range(2048))]\n",
    "df[morgan2_cols] = df.fingerprint.to_list()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Trainieren und Evaluieren des eigenen ML-Modells\n",
    "\n",
    "Zunächst wird euer Datensatz in Trainings- und Testset aufgeteilt und anschließend in X- (Input) und y-Werte (Zielvariable) unterteilt, da ein Modell immer als Funktion \\(f(X) = y\\) betrachtet werden kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training und Testdaten aufteilen\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['y_true_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen unserer Daten in Merkmale (X) und Zielvariable (y)\n",
    "morgan2_cols = ['morgan2_b'+str(i) for i in list(range(2048))]\n",
    "X_train = train_df[morgan2_cols] \n",
    "y_train = train_df.y_true_label\n",
    "X_test = test_df[morgan2_cols]\n",
    "y_test = test_df.y_true_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun erstellt ihr euer eigenes Modell und startet das Training mit `model.fit`, indem ihr das Modell mit eurem Trainingsdatensatz füttert. Zunächst legt ihr jedoch das Grundgerüst für die verschiedenen Modelltypen fest, indem ihr die entsprechende Funktion bei `model =` einfügt. (Ihr könnt die Basiseinstellungen der Modelle gerne noch anpassen – schaut dafür in die Dokumentation der jeweiligen Funktion im Netz.)\n",
    "\n",
    "\n",
    "```python\n",
    "RF  = RandomForestClassifier(n_estimators=100, random_state=42) # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "SVM = SVC(kernel='rbf', probability=True, random_state=42) # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "KNN = KNeighborsClassifier(n_neighbors=5) # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "NN  = MLPClassifier(hidden_layer_sizes=(1048, 256), activation='relu', solver='adam', max_iter=300, random_state=42) # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere das Modell\n",
    "model = HIER_EUER_MODELL_ALS_FUNKTION\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu prüfen, wie gut euer Modell funktioniert, erstellen wir nun eine **ROC-Kurve** (Receiver Operating Characteristic), die die Vorhersageleistung visualisiert und die Fähigkeit des Modells zeigt, zwischen den Klassen zu unterscheiden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a figure for plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve points and AUC\n",
    "fpr, tpr, thresholds = roc_curve(test_df['y_true_label'], y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaut nun, ob ihr die Kennwerte aus der Einführung berechnen könnt, indem ihr folgende Variablen verwendet:  \n",
    "\n",
    "- `X_test` = die Input-Werte des Testsets  \n",
    "- `y_test` = die wahren Labels des Testsets  \n",
    "- `y_pred_prob[:, 1]` = die vom Modell vorhergesagten Wahrscheinlichkeiten für die positive Klasse  \n",
    "\n",
    "Die zu berechnenden Kennwerte sind: **Accuracy, Precision, Recall und Specificity**. \n",
    "\n",
    "- Zum Addieren nutzt ihr `+`  \n",
    "- Zum Subtrahieren nutzt ihr `-`  \n",
    "- Zum Multiplizieren nutzt ihr `*`  \n",
    "- Zum Dividieren nutzt ihr `/`\n",
    "\n",
    "*BONUS*: Finde therausfinden was der F1 Score ist, wie man ihn berrechnet und warum man diesen gern nutzt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel für eine rechnung 1 + 1 * 1 / 1 in Python\n",
    "result = 1 + 1 * 1 / 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = RECHNUNG_HIER_EINFÜGEN\n",
    "precision = RECHNUNG_HIER_EINFÜGEN\n",
    "recall = RECHNUNG_HIER_EINFÜGEN\n",
    "specificity = RECHNUNG_HIER_EINFÜGEN\n",
    "\n",
    "print(f\"\"\"Accuracy: {accuracy}\n",
    "Precision: {precision}\n",
    "Recall: {recall}\n",
    "Specificity: {specificity}\n",
    "\"\"\")\n",
    "\n",
    "# HIER BONUS CODE EINFÜGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Screening der DrugBank\n",
    "\n",
    "Nun nutzen wir unser ML-Modell, um die **DrugBank** zu screenen. Das Modell soll dabei Moleküle identifizieren, die an euer Target wahrscheinlich aktiv sind.\n",
    "\n",
    "Zuerst generieren wir für die DrugBank-Moleküle Fingerprints mit derselben Funktion wie für unser Trainingsset, damit Länge und Aufbau der X-Werte konsistent bleiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugbank['fingerprint'] = df_drugbank['preprocessedSmiles'].apply(lambda x: mol2fingerprint(Chem.MolFromSmiles(x)))\n",
    "df_drugbank = df_drugbank.assign(mol=df_drugbank['preprocessedSmiles'].apply(Chem.MolFromSmiles))   \n",
    "df_drugbank[morgan2_cols] = df_drugbank.fingerprint.to_list()\n",
    "X = df_drugbank[morgan2_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun nutzen wir unser Modell, um vorherzusagen, welche Moleküle in der DrugBank an unserem Target aktiv sein könnten, und prüfen anschließend auf der Webseite der DrugBank, wie gut unsere Vorhersagen mit den bekannten Daten übereinstimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba = model.predict_proba(X)[:, 1]\n",
    "df_drugbank['Predicted_result'] = predictions_proba\n",
    "\n",
    "# Sortieren nach welcher klasse unser molekül zugeordnet wurde und Anzeige der ersten 20 Verbindungen\n",
    "df_drugbank[['DATABASE_ID','mol', 'Predicted_result']].sort_values(by='Predicted_result', ascending=False).head(20)\n",
    "\n",
    "# Überprüft die database_id und schaut aufder DrugBank website nach euren Molekülen: https://go.drugbank.com/\n",
    "# Schlägt das Modell sinvolle Dinge vor? (*w*) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier könnt ihr euch eure **Top 50 Vorhersagen** noch einmal als chemische Strukturen anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top 20 predictions in rdkit gird\n",
    "def show_top_50_predictions(df, column):\n",
    "    # Get the top 50 predictions\n",
    "    top_50 = df.nlargest(50, column)\n",
    "    \n",
    "    # Create a list of molecules\n",
    "    mols = [Chem.MolFromSmiles(smiles) for smiles in top_50['preprocessedSmiles']]\n",
    "    \n",
    "    # Draw the molecules in a grid\n",
    "    img = Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200))\n",
    "    \n",
    "    return img\n",
    "# Display the top 20 predictions\n",
    "img = show_top_50_predictions(df_drugbank, 'Predicted_result')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Screening bisher unerforschter Moleküle\n",
    "\n",
    "Als letztes nutzt ihr euer Modell, um aus einer Datenbank bisher unerforschter Moleküle Vorhersagen zu treffen und potenziell neue Wirkstoffe für euer Target zu identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
